# QLORA_Assignment
Our repository demonstrates how to fine-tune a base language model using QLoRA and PEFT on the OpenAssistant dataset. It leverages the microsoft/phi-2 model as the base and applies a LoRA adapter fine-tuned from Anubis97/FinetuningPhi-97 with 4-bit quantization (NF4) to achieve parameter-efficient training. The training process uses SFTTrainer from TRL and evaluates model performance using perplexity on a subset of validation data. Data is prepared by formatting samples with role-based prompts and tokenizing them to a fixed maximum length, and after training the final model and adapter are saved for subsequent inference.
